{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/r-doz/PML2025/blob/main/./04_exact_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "id": "e99d43cb4329de73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exact inference with Belief Propagation\n",
    "\n",
    "Tavano Matteo SM3800057 First PML homework\n",
    "\n",
    "\n",
    "This notebook is inspired from [Jessica Stringham's work](https://jessicastringham.net)"
   ],
   "id": "e7f29e9bf4d4c48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Exercise 6: Extending Belief Propagation to the Sum-Product Algorithm\n",
    "\n",
    "In the notebook *\"Exact Inference with Belief Propagation\"*, we previously computed the marginal distribution of a given variable using the message-passing method. Now, we aim to extend this implementation to the sum-product algorithm.\n",
    "\n",
    "1. **Extend the `Messages` class** by adding the following methods:\n",
    "   - **`forward`**: Computes the forward pass.\n",
    "   - **`backward`**: Computes the backward pass.\n",
    "   - **`belief_propagation`**: Executes the forward and backward passes, then uses the computed messages to determine all marginal distributions. This method should return a dictionary mapping each variable name to its corresponding marginal distribution.\n",
    "\n",
    "2. **Apply the `belief_propagation` method** to compute the marginal distributions of the variables in the factor graph described on page 43 of the course notes.\n",
    "\n",
    "For this exercise, please submit the updated notebook **`04_exact_inference.ipynb`**, including your additional code.\n",
    "\n",
    "**NOTE: Make sure to add comments to all the code you write!**"
   ],
   "id": "64fa64ec00e7e341"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:11:51.350656Z",
     "start_time": "2025-04-13T14:11:51.335468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# libraries import\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque"
   ],
   "id": "fdb548771ac8ee43",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Distribution",
   "id": "ff3acb2eb792a983"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:11:53.587684Z",
     "start_time": "2025-04-13T14:11:53.563682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Distribution():\n",
    "    \"\"\"\n",
    "    Discrete probability distributions, expressed using labeled arrays\n",
    "    probs: array of probability values\n",
    "    axes_labels: list of axes names\n",
    "    \"\"\"\n",
    "    def __init__(self, probs, axes_labels):\n",
    "        # Ensure probs is a numpy array\n",
    "        self.probs = np.asarray(probs)\n",
    "        self.axes_labels = axes_labels\n",
    "\n",
    "    def get_axes(self):\n",
    "        #returns a dictionary with axes names and the corresponding coordinates\n",
    "        return {name: axis for axis, name in enumerate(self.axes_labels)}\n",
    "\n",
    "    def get_other_axes_from(self, axis_label):\n",
    "        #returns a tuple containing all the axes coordinates except from axis_label\n",
    "        axis_to_keep = self.get_axes().get(axis_label)\n",
    "        if axis_to_keep is None:\n",
    "             raise ValueError(f\"Axis label '{axis_label}' not found in {self.axes_labels}\")\n",
    "        return tuple(axis for axis, name in enumerate(self.axes_labels) if name != axis_label)\n",
    "\n",
    "    def is_valid_conditional(self, variable_name):\n",
    "        #variable_name is the name of the variable for which we are computing the distribution, e.g. in p(y|x) it is 'y'\n",
    "        axis_to_sum = self.get_axes().get(variable_name)\n",
    "        if axis_to_sum is None:\n",
    "            # Handle case where the distribution might be p(x) and variable_name is 'x'\n",
    "             if len(self.axes_labels) == 1 and self.axes_labels[0] == variable_name:\n",
    "                 axis_to_sum = 0 # For single variable distributions p(x)\n",
    "             else:\n",
    "                print(f\"Warning: Variable '{variable_name}' not found in axes {self.axes_labels} for conditional check.\")\n",
    "                return False\n",
    "\n",
    "        # Handle scalar distributions (like prior factors with fixed value)\n",
    "        if self.probs.ndim == 0:\n",
    "             return np.isclose(self.probs, 1.0) # A single probability must be 1 to be valid \"conditional\" on itself\n",
    "\n",
    "        # Ensure sums are close to 1.0 across the specified axis\n",
    "        try:\n",
    "            sums = np.sum(self.probs, axis=axis_to_sum)\n",
    "            return np.all(np.isclose(sums, 1.0))\n",
    "        except np.AxisError:\n",
    "             print(f\"Error: Axis {axis_to_sum} out of bounds for array with shape {self.probs.shape}\")\n",
    "             return False\n",
    "\n",
    "    def is_valid_joint(self):\n",
    "        # Check if the sum over all elements is close to 1.0\n",
    "        return np.isclose(np.sum(self.probs), 1.0)"
   ],
   "id": "d47d75a98ecd3338",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:11:55.830577Z",
     "start_time": "2025-04-13T14:11:55.798608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# function to allow multiplications between distributions\n",
    "def multiply(p_dist1, p_dist2):\n",
    "    '''\n",
    "    Compute the product of two distributions p1(vars1) * p2(vars2).\n",
    "    Handles alignment and broadcasting based on shared variable names.\n",
    "    Returns a new Distribution.\n",
    "\n",
    "    Example:\n",
    "    p1(a, b), p2(b, c) -> result(a, b, c)\n",
    "    p1(a), p2(b) -> result(a, b)\n",
    "    p1(a, b), p2(b) -> result(a, b)\n",
    "    '''\n",
    "    # Ensure both inputs are Distribution objects\n",
    "    if not isinstance(p_dist1, Distribution):\n",
    "        raise TypeError(\"p_dist1 must be a Distribution object\")\n",
    "    if not isinstance(p_dist2, Distribution):\n",
    "        raise TypeError(\"p_dist2 must be a Distribution object\")\n",
    "\n",
    "    # Combine axes labels, preserving order and uniqueness\n",
    "    # Start with p_dist1's labels\n",
    "    new_axes_labels = list(p_dist1.axes_labels)\n",
    "    # Add any labels from p_dist2 not already present\n",
    "    for label in p_dist2.axes_labels:\n",
    "        if label not in new_axes_labels:\n",
    "            new_axes_labels.append(label)\n",
    "\n",
    "    # Determine shape for broadcasting/alignment\n",
    "    # For each distribution, create a shape tuple aligned with new_axes_labels\n",
    "    # Dimensions corresponding to axes *not* in the original distribution will be 1\n",
    "    shape1 = []\n",
    "    map1 = np.arange(len(p_dist1.axes_labels)) # Original axes indices\n",
    "    target_map1 = [] # Target axes indices in the new combined shape\n",
    "    for label in new_axes_labels:\n",
    "        if label in p_dist1.axes_labels:\n",
    "            axis_index = p_dist1.axes_labels.index(label)\n",
    "            shape1.append(p_dist1.probs.shape[axis_index])\n",
    "            target_map1.append(axis_index) # Track where this original axis goes\n",
    "        else:\n",
    "            shape1.append(1)\n",
    "            # No corresponding original axis, placeholder\n",
    "\n",
    "    shape2 = []\n",
    "    map2 = np.arange(len(p_dist2.axes_labels))\n",
    "    target_map2 = []\n",
    "    for label in new_axes_labels:\n",
    "        if label in p_dist2.axes_labels:\n",
    "            axis_index = p_dist2.axes_labels.index(label)\n",
    "            shape2.append(p_dist2.probs.shape[axis_index])\n",
    "            target_map2.append(axis_index)\n",
    "        else:\n",
    "            shape2.append(1)\n",
    "\n",
    "    # Use reshape and transpose carefully if axes order changes significantly,\n",
    "    # but simple reshape works if we just add singleton dimensions.\n",
    "    try:\n",
    "        reshaped_probs1 = p_dist1.probs.reshape(tuple(shape1))\n",
    "    except ValueError:\n",
    "        # If reshape fails, likely means axes order mismatch. Need transpose.\n",
    "        current_to_new_map1 = {label: i for i, label in enumerate(new_axes_labels) if label in p_dist1.axes_labels}\n",
    "        transpose_order1 = [p_dist1.axes_labels.index(label) for label in new_axes_labels if label in p_dist1.axes_labels]\n",
    "        # We need to align p_dist1.probs axes to match the order in new_axes_labels where they exist\n",
    "        # This is complex. Let's stick to the simpler broadcasting assumption first.\n",
    "        # Fallback: Use explicit dimension expansion with np.expand_dims or slicing.\n",
    "\n",
    "        # Simpler approach: Add singleton dimensions using slicing\n",
    "        aligned_probs1 = p_dist1.probs\n",
    "        current_axes1 = list(p_dist1.axes_labels)\n",
    "        for i, label in enumerate(new_axes_labels):\n",
    "             if label not in current_axes1:\n",
    "                  aligned_probs1 = np.expand_dims(aligned_probs1, axis=i)\n",
    "                  current_axes1.insert(i, label) # Keep track of inserted axes\n",
    "        # Now need to reorder if necessary - this gets complex fast.\n",
    "        # Let's assume the reshape approach works for typical cases.\n",
    "        # Re-raising the original error if assumption fails.\n",
    "        raise ValueError(f\"Reshape failed for p_dist1. Check axes alignment. Shape: {p_dist1.probs.shape}, Target Shape: {shape1}\") from None\n",
    "\n",
    "    try:\n",
    "        reshaped_probs2 = p_dist2.probs.reshape(tuple(shape2))\n",
    "    except ValueError:\n",
    "         # Similar issue for p_dist2\n",
    "         raise ValueError(f\"Reshape failed for p_dist2. Check axes alignment. Shape: {p_dist2.probs.shape}, Target Shape: {shape2}\") from None\n",
    "\n",
    "\n",
    "    # Perform element-wise multiplication (broadcasting handles the rest)\n",
    "    result_probs = reshaped_probs1 * reshaped_probs2\n",
    "\n",
    "    return Distribution(result_probs, new_axes_labels)"
   ],
   "id": "f064928fad0db6d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Notes** Refactored using Gemini 2.5",
   "id": "420776eaf1c5ced4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Node",
   "id": "346331ff908b05e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:12:01.354644Z",
     "start_time": "2025-04-13T14:12:01.338785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Node(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.neighbors = [] # Stores neighboring Node objects\n",
    "\n",
    "    def is_valid_neighbor(self, neighbor):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def add_neighbor(self, neighbor):\n",
    "        if not self.is_valid_neighbor(neighbor):\n",
    "             raise TypeError(f\"Cannot add {type(neighbor)} as neighbor to {type(self)}\")\n",
    "        if neighbor not in self.neighbors:\n",
    "            self.neighbors.append(neighbor)"
   ],
   "id": "d08f9d1988850362",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Variable",
   "id": "dee7c7dec0f8ed1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:12:03.066573Z",
     "start_time": "2025-04-13T14:12:03.052915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Variable(Node):\n",
    "    def __init__(self, name):\n",
    "        super(Variable, self).__init__(name)\n",
    "        self.observed_value = None # To handle observed evidence (index of observed state)\n",
    "\n",
    "    def is_valid_neighbor(self, factor):\n",
    "        return isinstance(factor, Factor)  # Variables can only neighbor Factors\n",
    "\n",
    "    def observe(self, value):\n",
    "        \"\"\"Sets the observed value (state index) for this variable.\"\"\"\n",
    "        self.observed_value = value\n",
    "\n",
    "    def unobserve(self):\n",
    "        \"\"\"Removes the observation for this variable.\"\"\"\n",
    "        self.observed_value = None"
   ],
   "id": "d5abe4bad34d4b16",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Factor",
   "id": "7f65a7ba1c0b7cb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:12:11.674048Z",
     "start_time": "2025-04-13T14:12:11.644543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Factor(Node):\n",
    "    def __init__(self, name):\n",
    "        super(Factor, self).__init__(name)\n",
    "        self.data = None # Should store a Distribution object\n",
    "\n",
    "    def is_valid_neighbor(self, variable):\n",
    "        return isinstance(variable, Variable)  # Factors can only neighbor Variables"
   ],
   "id": "4b2566ade1713932",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parser",
   "id": "751dd827d9133a27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:12:13.651514Z",
     "start_time": "2025-04-13T14:12:13.627749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ParsedTerm = namedtuple('ParsedTerm', [\n",
    "    'term',      # e.g., 'p(a|b,c)'\n",
    "    'var_name',  # list of non-conditioned vars, e.g., ['a']\n",
    "    'given',     # list of conditioned vars, e.g., ['b', 'c']\n",
    "])\n",
    "\n",
    "def _parse_term(term_content):\n",
    "    # Given content like 'a|b,c' or 'x,y|z' or 'k'\n",
    "    # returns ([vars], [given])\n",
    "    if '|' in term_content:\n",
    "        var_part, given_part = term_content.split('|', 1)\n",
    "        vars_ = [v.strip() for v in var_part.split(',') if v.strip()]\n",
    "        given_ = [g.strip() for g in given_part.split(',') if g.strip()]\n",
    "    else:\n",
    "        vars_ = [v.strip() for v in term_content.split(',') if v.strip()]\n",
    "        given_ = []\n",
    "    # Ensure no empty strings resulted from parsing (e.g., 'p(a,)')\n",
    "    if any(not v for v in vars_) or any(not g for g in given_):\n",
    "         raise ValueError(f\"Invalid variable format in term content: '{term_content}'\")\n",
    "    return vars_, given_\n",
    "\n",
    "def _parse_model_string_into_terms(model_string):\n",
    "    terms = []\n",
    "    # Split by 'p(' but handle potential edge cases like starting 'p('\n",
    "    parts = model_string.strip().split('p(')\n",
    "    if not parts[0].isspace() and parts[0] != \"\":\n",
    "         raise ValueError(\"Model string should start with 'p(' or factors separated by 'p('.\")\n",
    "\n",
    "    for part in parts[1:]: # Skip the potentially empty part before the first 'p('\n",
    "        if not part: continue # Skip empty strings resulting from split\n",
    "\n",
    "        if ')' not in part:\n",
    "             raise ValueError(f\"Invalid term format in: '{part}'. Missing closing parenthesis.\")\n",
    "\n",
    "        # Extract content inside parentheses and the full term name\n",
    "        try:\n",
    "            term_content, rest = part.split(')', 1) # Split only on the first ')'\n",
    "        except ValueError:\n",
    "             raise ValueError(f\"Invalid term format in: '{part}'. Malformed content.\")\n",
    "\n",
    "        term_name = f\"p({term_content})\"\n",
    "\n",
    "        vars_, given_ = _parse_term(term_content)\n",
    "        if not vars_: # Must have at least one variable, e.g. p() is invalid\n",
    "             raise ValueError(f\"Term '{term_name}' must contain at least one variable.\")\n",
    "\n",
    "        terms.append(ParsedTerm(term_name, vars_, given_))\n",
    "    if not terms:\n",
    "        raise ValueError(\"Model string did not contain any valid factor terms.\")\n",
    "    return terms\n",
    "\n",
    "\n",
    "def parse_model_into_variables_and_factors(model_string):\n",
    "    parsed_terms = _parse_model_string_into_terms(model_string)\n",
    "\n",
    "    variables = {} # Map variable name (str) to Variable object\n",
    "    factors = []   # List of Factor objects\n",
    "\n",
    "    # First pass: Identify all unique variables\n",
    "    all_var_names = set()\n",
    "    for parsed_term in parsed_terms:\n",
    "        all_var_names.update(parsed_term.var_name)\n",
    "        all_var_names.update(parsed_term.given)\n",
    "\n",
    "    if not all_var_names:\n",
    "         raise ValueError(\"No variables found in the model string.\")\n",
    "\n",
    "    # Create Variable objects\n",
    "    for var_name in all_var_names:\n",
    "        variables[var_name] = Variable(var_name)\n",
    "\n",
    "    # Second pass: Create Factor objects and link them to Variables\n",
    "    factor_names = set()\n",
    "    for parsed_term in parsed_terms:\n",
    "        if parsed_term.term in factor_names:\n",
    "            raise ValueError(f\"Duplicate factor name found: {parsed_term.term}. Factors must be unique.\")\n",
    "        factor_names.add(parsed_term.term)\n",
    "\n",
    "        new_factor = Factor(parsed_term.term)\n",
    "        factors.append(new_factor)\n",
    "\n",
    "        # Link factor to its variables and vice-versa\n",
    "        factor_vars_names = parsed_term.var_name + parsed_term.given\n",
    "        if not factor_vars_names:\n",
    "             raise ValueError(f\"Factor '{new_factor.name}' is not connected to any variables.\")\n",
    "\n",
    "        for var_name in factor_vars_names:\n",
    "            if var_name not in variables:\n",
    "                 # This should not happen if parsing was correct, but check anyway\n",
    "                 raise ValueError(f\"Variable '{var_name}' needed by factor '{new_factor.name}' was not identified.\")\n",
    "            variable_obj = variables[var_name]\n",
    "            new_factor.add_neighbor(variable_obj)\n",
    "            variable_obj.add_neighbor(new_factor) # Link back\n",
    "\n",
    "    return factors, variables"
   ],
   "id": "f5aa6dfb5f204ee",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PGM",
   "id": "3ffaba9486fffe4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:12:17.157388Z",
     "start_time": "2025-04-13T14:12:17.141709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PGM(object):\n",
    "    def __init__(self, factors, variables):\n",
    "        self._factors = {f.name: f for f in factors} # Store factors in a dict by name\n",
    "        self._variables = variables # Dict mapping name to Variable object\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, model_string):\n",
    "        factors_list, variables_dict = parse_model_into_variables_and_factors(model_string)\n",
    "        return PGM(factors_list, variables_dict)\n",
    "\n",
    "    def set_distributions(self, data):\n",
    "        \"\"\"\n",
    "        Assigns Distribution objects to factors.\n",
    "        Input `data` is a dictionary mapping factor names (str) to Distribution objects.\n",
    "        \"\"\"\n",
    "        var_dims = {} # Store expected dimension size for each variable axis\n",
    "        assigned_factors = set()\n",
    "        for factor_name, factor_data in data.items():\n",
    "            if factor_name not in self._factors:\n",
    "                # Check for slight variations like missing spaces if desired, but strict match is safer.\n",
    "                raise ValueError(f\"Factor name '{factor_name}' from data not found in PGM factors: {list(self._factors.keys())}\")\n",
    "\n",
    "            factor = self._factors[factor_name]\n",
    "            assigned_factors.add(factor_name)\n",
    "\n",
    "            if not isinstance(factor_data, Distribution):\n",
    "                 raise TypeError(f\"Data for factor '{factor_name}' must be a Distribution object, got {type(factor_data)}.\")\n",
    "\n",
    "            # Check if the axes labels in the distribution match the factor's neighbors\n",
    "            factor_neighbor_names = set(v.name for v in factor.neighbors)\n",
    "            distribution_axes_names = set(factor_data.axes_labels)\n",
    "\n",
    "            if distribution_axes_names != factor_neighbor_names:\n",
    "                missing_axes = factor_neighbor_names - distribution_axes_names\n",
    "                extra_axes = distribution_axes_names - factor_neighbor_names\n",
    "                error_msg = f\"Axes mismatch for factor '{factor_name}': \"\n",
    "                if missing_axes: error_msg += f\"Distribution missing axes for variables {missing_axes}. Expected axes based on neighbors: {factor_neighbor_names}. Got: {distribution_axes_names}.\"\n",
    "                if extra_axes: error_msg += f\"Distribution has extra axes {extra_axes} not connected to factor. Expected axes based on neighbors: {factor_neighbor_names}. Got: {distribution_axes_names}.\"\n",
    "                raise ValueError(error_msg)\n",
    "\n",
    "            # Check and record dimension sizes for consistency\n",
    "            if not hasattr(factor_data.probs, 'shape'):\n",
    "                 raise ValueError(f\"Factor data 'probs' for '{factor_name}' has no shape attribute.\")\n",
    "\n",
    "            # Ensure the number of dimensions matches the number of labels\n",
    "            if len(factor_data.probs.shape) != len(factor_data.axes_labels):\n",
    "                raise ValueError(f\"Dimension mismatch for factor '{factor_name}': Number of axes labels ({len(factor_data.axes_labels)}) does not match number of probability dimensions ({len(factor_data.probs.shape)}).\")\n",
    "\n",
    "            for var_name, dim_size in zip(factor_data.axes_labels, factor_data.probs.shape):\n",
    "                if var_name not in self._variables:\n",
    "                    # Should not happen if parsing is correct\n",
    "                     raise ValueError(f\"Variable '{var_name}' from factor '{factor_name}' axes not found in global variable list.\")\n",
    "\n",
    "                if var_name not in var_dims:\n",
    "                    var_dims[var_name] = dim_size\n",
    "                    self._variables[var_name].dim = dim_size # Store dimension on variable node\n",
    "                elif var_dims[var_name] != dim_size:\n",
    "                    raise ValueError(\n",
    "                        f\"Inconsistent dimension size for variable '{var_name}'. \"\n",
    "                        f\"Factor '{factor_name}' expects size {dim_size}, \"\n",
    "                        f\"but previously seen size was {var_dims[var_name]}.\"\n",
    "                    )\n",
    "\n",
    "            factor.data = factor_data # Assign the distribution to the factor\n",
    "\n",
    "        # Check if all factors in the PGM were assigned data\n",
    "        missing_data = set(self._factors.keys()) - assigned_factors\n",
    "        if missing_data:\n",
    "             print(f\"Warning: Distributions were not provided for all factors: {missing_data}\")\n",
    "\n",
    "\n",
    "    def variable_from_name(self, var_name):\n",
    "        if var_name not in self._variables:\n",
    "            raise KeyError(f\"Variable '{var_name}' not found in the PGM.\")\n",
    "        return self._variables[var_name]\n",
    "\n",
    "    def factor_from_name(self, factor_name):\n",
    "        if factor_name not in self._factors:\n",
    "             raise KeyError(f\"Factor '{factor_name}' not found in the PGM.\")\n",
    "        return self._factors[factor_name]\n",
    "\n",
    "    def get_variables(self):\n",
    "        \"\"\"Returns the dictionary of variables {name: Variable}.\"\"\"\n",
    "        return self._variables\n",
    "\n",
    "    def get_factors(self):\n",
    "        \"\"\"Returns the dictionary of factors {name: Factor}.\"\"\"\n",
    "        return self._factors"
   ],
   "id": "bd119d4621d5c32e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Notes:** getter methods added",
   "id": "bdeed7aed1503ce2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Messages",
   "id": "e11f3c82be85a09c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:12:20.316031Z",
     "start_time": "2025-04-13T14:12:20.284100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Messages(object):\n",
    "    def __init__(self):\n",
    "        self.messages = {} # Memoization cache: key=(sender_name, receiver_name), value=message_array\n",
    "\n",
    "    def _get_message_key(self, sender, receiver):\n",
    "        \"\"\"Helper to create a consistent key for the messages dictionary.\"\"\"\n",
    "        return (sender.name, receiver.name)\n",
    "\n",
    "    def _get_variable_dimension(self, variable, context_node):\n",
    "        \"\"\" Tries to infer the dimension (number of states) of a variable. \"\"\"\n",
    "        if hasattr(variable, 'dim'):\n",
    "            return variable.dim\n",
    "        # Infer from context node (neighbor factor or variable)\n",
    "        if isinstance(context_node, Factor) and context_node.data:\n",
    "             try:\n",
    "                 axis_index = context_node.data.axes_labels.index(variable.name)\n",
    "                 return context_node.data.probs.shape[axis_index]\n",
    "             except (ValueError, IndexError):\n",
    "                 pass # Variable not in this factor's data or data malformed\n",
    "        # Try inferring from other neighbors\n",
    "        for neighbor in variable.neighbors:\n",
    "            if neighbor != context_node and isinstance(neighbor, Factor) and neighbor.data:\n",
    "                try:\n",
    "                    axis_index = neighbor.data.axes_labels.index(variable.name)\n",
    "                    dim = neighbor.data.probs.shape[axis_index]\n",
    "                    variable.dim = dim # Cache dimension on variable node\n",
    "                    return dim\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "        raise RuntimeError(f\"Could not determine dimension for variable '{variable.name}' from neighbors.\")\n",
    "\n",
    "\n",
    "    def _variable_to_factor_messages(self, variable, factor):\n",
    "        \"\"\"\n",
    "        Computes the message from a variable node to a factor node.\n",
    "        message(var -> fac) = product of messages from all other factors linked to var.\n",
    "                              = product_{fac' in neighbors(var) \\ {fac}} message(fac' -> var)\n",
    "        Handles observed variables.\n",
    "        \"\"\"\n",
    "        # Key is already checked by the public wrapper method\n",
    "\n",
    "        # Check for observed variable\n",
    "        if variable.observed_value is not None:\n",
    "             var_dim = self._get_variable_dimension(variable, factor)\n",
    "             message = np.zeros(var_dim)\n",
    "             if 0 <= variable.observed_value < var_dim:\n",
    "                  message[variable.observed_value] = 1.0\n",
    "             else:\n",
    "                 raise ValueError(f\"Observed value {variable.observed_value} for variable '{variable.name}' is out of bounds for dimension {var_dim}.\")\n",
    "             # print(f\"  Observed Msg Var({variable.name}) -> Fac({factor.name}): {message}\") # Debug\n",
    "        else:\n",
    "            # Get messages from all other neighboring factors\n",
    "            incoming_messages = []\n",
    "            for neighbor_factor in variable.neighbors:\n",
    "                if neighbor_factor.name == factor.name:\n",
    "                    continue # Skip the factor we are sending the message to\n",
    "                # Recursively compute/retrieve the message from that factor to this variable\n",
    "                incoming_message = self.factor_to_variable_message(neighbor_factor, variable)\n",
    "                incoming_messages.append(incoming_message)\n",
    "\n",
    "            # Compute the product of incoming messages\n",
    "            if not incoming_messages:\n",
    "                # If the variable is a leaf node (only connected to 'factor'), message is uniform (array of ones)\n",
    "                var_dim = self._get_variable_dimension(variable, factor)\n",
    "                message = np.ones(var_dim)\n",
    "            else:\n",
    "                # Product of all incoming messages. Assumes messages are 1D arrays.\n",
    "                try:\n",
    "                    # Stack messages into a 2D array for prod along axis 0\n",
    "                    message_array = np.array(incoming_messages)\n",
    "                    # Check for empty arrays or inconsistent shapes if necessary\n",
    "                    if message_array.size == 0: # Handle case where incoming messages resulted in empty arrays (e.g., contradictions)\n",
    "                        var_dim = self._get_variable_dimension(variable, factor)\n",
    "                        message = np.zeros(var_dim) # Or handle as error?\n",
    "                    else:\n",
    "                         message = np.prod(message_array, axis=0)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error computing product for messages into Var({variable.name}) from factors other than Fac({factor.name}): {incoming_messages}\")\n",
    "                    raise e\n",
    "\n",
    "        # Normalize message? No, standard BP doesn't normalize var->fac messages.\n",
    "\n",
    "        # Memoization is handled by the public wrapper method\n",
    "        return message\n",
    "\n",
    "    def _factor_to_variable_messages(self, factor, variable):\n",
    "        \"\"\"\n",
    "        Computes the message from a factor node to a variable node.\n",
    "        message(fac -> var) = sum_{vars in fac \\ {var}} [ factor_potential * product_{var' in neighbors(fac) \\ {var}} message(var' -> fac) ]\n",
    "        \"\"\"\n",
    "        # Key is already checked by the public wrapper method\n",
    "\n",
    "        # Start with the factor's potential (distribution)\n",
    "        if factor.data is None:\n",
    "            raise ValueError(f\"Factor '{factor.name}' does not have distribution data set.\")\n",
    "\n",
    "        # Make a copy to avoid modifying the original factor data\n",
    "        current_potential = Distribution(np.copy(factor.data.probs), list(factor.data.axes_labels))\n",
    "\n",
    "        # Multiply by incoming messages from all other neighboring variables\n",
    "        other_neighbor_variables = [v for v in factor.neighbors if v.name != variable.name]\n",
    "\n",
    "        for neighbor_variable in other_neighbor_variables:\n",
    "            # Get the message from this neighbor variable to the factor\n",
    "            incoming_message = self.variable_to_factor_messages(neighbor_variable, factor)\n",
    "\n",
    "            # Multiply the current potential by this message.\n",
    "            message_dist = Distribution(incoming_message, [neighbor_variable.name])\n",
    "            try:\n",
    "                 current_potential = multiply(current_potential, message_dist) # Use the generalized multiply\n",
    "            except ValueError as e:\n",
    "                 print(f\"Error multiplying potential for Fac({factor.name}) with message from Var({neighbor_variable.name})\")\n",
    "                 print(f\"  Potential: labels={current_potential.axes_labels}, shape={current_potential.probs.shape}\")\n",
    "                 print(f\"  Message: labels={message_dist.axes_labels}, shape={message_dist.probs.shape}\")\n",
    "                 raise e\n",
    "\n",
    "\n",
    "        # Sum over all variables connected to the factor EXCEPT the target variable\n",
    "        vars_to_sum_out = [v.name for v in other_neighbor_variables]\n",
    "        axes_to_sum_out = []\n",
    "        potential_axes_map = current_potential.get_axes()\n",
    "        for var_name in vars_to_sum_out:\n",
    "             if var_name in potential_axes_map:\n",
    "                  axes_to_sum_out.append(potential_axes_map[var_name])\n",
    "             else:\n",
    "                 # This variable might have been introduced by a message multiplication\n",
    "                 # and might have dimension 1 if it wasn't part of original factor\n",
    "                 # Check shape to be sure\n",
    "                 if var_name in current_potential.axes_labels:\n",
    "                      axis_idx = current_potential.axes_labels.index(var_name)\n",
    "                      if current_potential.probs.shape[axis_idx] == 1:\n",
    "                           axes_to_sum_out.append(axis_idx) # Sum out singleton dimensions too\n",
    "                      else:\n",
    "                           # Should not happen if graph/messages are correct\n",
    "                           print(f\"Warning: Variable '{var_name}' to sum out in Fac({factor.name}) -> Var({variable.name}) has dimension > 1 but was not in original factor neighbors.\")\n",
    "                 # else: Variable not present, cannot sum out.\n",
    "\n",
    "        # Perform the summation\n",
    "        if axes_to_sum_out:\n",
    "            # Use tuple for summing over multiple axes, ensure axes are unique and valid\n",
    "            unique_axes_to_sum = tuple(sorted(list(set(axes_to_sum_out)), reverse=True)) # Sum largest axes first potentially helps\n",
    "            if not all(0 <= ax < current_potential.probs.ndim for ax in unique_axes_to_sum):\n",
    "                 raise IndexError(f\"Invalid axis found in {unique_axes_to_sum} for potential with ndim={current_potential.probs.ndim} in Fac({factor.name}) -> Var({variable.name})\")\n",
    "            summed_probs = np.sum(current_potential.probs, axis=unique_axes_to_sum)\n",
    "        else:\n",
    "             # If no other variables to sum out (factor involves only target variable, or others were observed and handled?)\n",
    "             summed_probs = current_potential.probs\n",
    "\n",
    "        # Result should be 1D array corresponding to target variable's states.\n",
    "        # It might have leading/trailing dims of size 1 from the sum. Squeeze them.\n",
    "        final_message_probs = np.squeeze(summed_probs)\n",
    "\n",
    "        # Ensure the result is still an array, even if variable has only 1 state\n",
    "        if not isinstance(final_message_probs, np.ndarray):\n",
    "             final_message_probs = np.array([final_message_probs])\n",
    "        elif final_message_probs.ndim == 0: # Handle case where squeeze results in scalar\n",
    "             final_message_probs = final_message_probs.reshape(1,)\n",
    "\n",
    "        # print(f\"  Msg Fac({factor.name}) -> Var({variable.name}): {final_message_probs}\") # Debug\n",
    "\n",
    "        # Normalize message? No, standard BP doesn't normalize fac->var messages.\n",
    "\n",
    "        # Memoization is handled by the public wrapper method\n",
    "        return final_message_probs\n",
    "\n",
    "\n",
    "    def marginal(self, variable):\n",
    "        \"\"\"\n",
    "        Computes the marginal distribution for a given variable.\n",
    "        p(var) proportional to product_{fac in neighbors(var)} message(fac -> var)\n",
    "        Handles observed variables.\n",
    "        \"\"\"\n",
    "        if variable.observed_value is not None:\n",
    "             # If observed, the marginal is a delta function (one-hot)\n",
    "             var_dim = self._get_variable_dimension(variable, variable) # Pass variable as context\n",
    "             marginal_p = np.zeros(var_dim)\n",
    "             if 0 <= variable.observed_value < var_dim:\n",
    "                 marginal_p[variable.observed_value] = 1.0\n",
    "             else:\n",
    "                  # This case should be caught earlier by variable_to_factor message if observed value invalid\n",
    "                  print(f\"Warning: Observed value {variable.observed_value} for variable '{variable.name}' seems out of bounds ({var_dim}). Returning zeros.\")\n",
    "             return marginal_p\n",
    "\n",
    "        # If not observed, compute product of incoming messages from all neighbors\n",
    "        incoming_messages = []\n",
    "        if not variable.neighbors:\n",
    "            # Isolated variable - marginal is typically considered uniform or based on a prior if one exists\n",
    "            # In factor graph context, often means model is underspecified for this var.\n",
    "            print(f\"Warning: Variable '{variable.name}' has no factors connected. Cannot compute marginal belief from factors. Returning uniform.\")\n",
    "            # Cannot determine dimension without neighbors or prior info. Assuming dim 1? Risky.\n",
    "            # Let's try to get dim if it was stored during set_distributions\n",
    "            try:\n",
    "                var_dim = self._get_variable_dimension(variable, variable)\n",
    "                return np.ones(var_dim) / var_dim\n",
    "            except RuntimeError:\n",
    "                 print(f\"Error: Cannot determine dimension for isolated variable '{variable.name}'. Returning [1.0].\")\n",
    "                 return np.array([1.0])\n",
    "\n",
    "\n",
    "        for neighbor_factor in variable.neighbors:\n",
    "            incoming_message = self.factor_to_variable_message(neighbor_factor, variable)\n",
    "            # Ensure message is numpy array for stacking\n",
    "            if not isinstance(incoming_message, np.ndarray):\n",
    "                 incoming_message = np.array(incoming_message)\n",
    "            # Check if message is empty (e.g. due to contradiction)\n",
    "            if incoming_message.size == 0:\n",
    "                  print(f\"Warning: Received empty message from factor '{neighbor_factor.name}' to variable '{variable.name}'. Indicates potential contradiction. Marginal will be zero.\")\n",
    "                  var_dim = self._get_variable_dimension(variable, variable)\n",
    "                  return np.zeros(var_dim) # Belief is zero everywhere\n",
    "            incoming_messages.append(incoming_message)\n",
    "\n",
    "        # Product of messages\n",
    "        try:\n",
    "            message_array = np.array(incoming_messages)\n",
    "            if message_array.size == 0 : # Should be caught above, but double check\n",
    "                var_dim = self._get_variable_dimension(variable, variable)\n",
    "                unnorm_p = np.zeros(var_dim)\n",
    "            else:\n",
    "                unnorm_p = np.prod(message_array, axis=0)\n",
    "        except ValueError as e:\n",
    "             print(f\"Error computing product of incoming messages for variable '{variable.name}': {incoming_messages}\")\n",
    "             raise e\n",
    "\n",
    "\n",
    "        # Normalize to get a valid probability distribution\n",
    "        norm_const = np.sum(unnorm_p)\n",
    "        if np.isclose(norm_const, 0):\n",
    "            # Avoid division by zero. Indicates contradiction or zero probability event.\n",
    "            print(f\"Warning: Normalization constant is close to zero for variable '{variable.name}'. Belief is zero or ill-defined. Returning uniform distribution over inferred dimension.\")\n",
    "            var_dim = self._get_variable_dimension(variable, variable)\n",
    "            return np.ones(var_dim) / var_dim\n",
    "        else:\n",
    "            marginal_p = unnorm_p / norm_const\n",
    "\n",
    "        # Ensure result has the correct dimension, handle scalar case\n",
    "        var_dim = self._get_variable_dimension(variable, variable)\n",
    "        if marginal_p.shape != (var_dim,):\n",
    "            if marginal_p.size == var_dim: # Can be reshaped if size matches\n",
    "                try:\n",
    "                     marginal_p = marginal_p.reshape((var_dim,))\n",
    "                except ValueError:\n",
    "                      print(f\"Warning: Marginal shape mismatch for {variable.name}. Expected {(var_dim,)}, got {marginal_p.shape}. Check message calculations.\")\n",
    "            elif marginal_p.ndim == 0 and var_dim == 1: # Scalar result for dim 1 var\n",
    "                 marginal_p = np.array([marginal_p])\n",
    "            else:\n",
    "                print(f\"Warning: Marginal shape mismatch for {variable.name}. Expected {(var_dim,)}, got {marginal_p.shape}. Check message calculations.\")\n",
    "\n",
    "\n",
    "        return marginal_p\n",
    "\n",
    "    # --- Public wrappers for message computation with memoization ---\n",
    "    def variable_to_factor_messages(self, variable, factor):\n",
    "         message_key = self._get_message_key(variable, factor)\n",
    "         if message_key not in self.messages:\n",
    "             # print(f\"Computing msg: Var({variable.name}) -> Fac({factor.name})\") # Debug\n",
    "             self.messages[message_key] = self._variable_to_factor_messages(variable, factor)\n",
    "         # else: print(f\"Using cached msg: Var({variable.name}) -> Fac({factor.name})\") # Debug\n",
    "         # Return a copy to prevent accidental modification of cached value\n",
    "         return np.copy(self.messages[message_key])\n",
    "\n",
    "    def factor_to_variable_message(self, factor, variable):\n",
    "         message_key = self._get_message_key(factor, variable)\n",
    "         if message_key not in self.messages:\n",
    "             # print(f\"Computing msg: Fac({factor.name}) -> Var({variable.name})\") # Debug\n",
    "             self.messages[message_key] = self._factor_to_variable_messages(factor, variable)\n",
    "         # else: print(f\"Using cached msg: Fac({factor.name}) -> Var({variable.name})\") # Debug\n",
    "         # Return a copy\n",
    "         return np.copy(self.messages[message_key])\n",
    "\n",
    "    # --- New methods for structured passes and full BP ---\n",
    "\n",
    "    def forward(self, pgm: PGM, root_variable_name: str):\n",
    "        \"\"\"\n",
    "        Computes messages flowing from the leaves towards the specified root variable.\n",
    "        This function primarily ensures that the necessary messages required for\n",
    "        calculating the marginal of the root (and potentially nodes \"downstream\"\n",
    "        from it in the backward pass) are computed, leveraging the lazy recursive approach.\n",
    "\n",
    "        Args:\n",
    "            pgm (PGM): The PGM object.\n",
    "            root_variable_name (str): The name of the variable to act as the root for this pass.\n",
    "        \"\"\"\n",
    "        print(f\"--- Running Forward Pass (towards root '{root_variable_name}') ---\")\n",
    "        if root_variable_name not in pgm.get_variables():\n",
    "             raise ValueError(f\"Root variable '{root_variable_name}' not found in PGM.\")\n",
    "\n",
    "        root_variable = pgm.variable_from_name(root_variable_name)\n",
    "\n",
    "        # Trigger the computation of messages incoming to the root variable.\n",
    "        # The recursive calls within factor_to_variable_message will propagate\n",
    "        # the computation requests towards the leaves as needed.\n",
    "        print(f\"Triggering message computations incoming to root '{root_variable_name}'...\")\n",
    "        for factor in root_variable.neighbors:\n",
    "             # Requesting this message triggers recursive calls towards leaves\n",
    "             _ = self.factor_to_variable_message(factor, root_variable)\n",
    "\n",
    "        print(f\"Forward pass towards '{root_variable_name}' complete (messages computed lazily).\")\n",
    "\n",
    "\n",
    "    def backward(self, pgm: PGM, root_variable_name: str):\n",
    "        \"\"\"\n",
    "        Computes messages flowing from the specified root variable out towards the leaves.\n",
    "        This relies on the forward pass having computed messages incoming to the root.\n",
    "        It triggers computations flowing outwards from the root.\n",
    "\n",
    "        Args:\n",
    "            pgm (PGM): The PGM object.\n",
    "            root_variable_name (str): The name of the variable acting as the root.\n",
    "        \"\"\"\n",
    "        print(f\"--- Running Backward Pass (from root '{root_variable_name}') ---\")\n",
    "        if root_variable_name not in pgm.get_variables():\n",
    "             raise ValueError(f\"Root variable '{root_variable_name}' not found in PGM.\")\n",
    "\n",
    "        root_variable = pgm.variable_from_name(root_variable_name)\n",
    "\n",
    "        # We need a way to traverse outwards from the root. BFS or DFS can work.\n",
    "        # Let's use a queue (BFS style) to manage nodes to process.\n",
    "        # We need to send messages outwards from the root.\n",
    "\n",
    "        queue = [(root_variable, None)] # Start with root, parent=None\n",
    "        visited_edges = set() # To avoid cycles in message passing (though should be tree)\n",
    "\n",
    "        print(f\"Triggering message computations outgoing from root '{root_variable_name}'...\")\n",
    "\n",
    "        while queue:\n",
    "            current_node, parent_node = queue.pop(0)\n",
    "\n",
    "            if isinstance(current_node, Variable):\n",
    "                # Send messages Variable -> Factor to all neighbors except the one towards parent_node\n",
    "                for neighbor_factor in current_node.neighbors:\n",
    "                    # The \"parent\" factor is the one connecting to parent_node (if current_node is not root)\n",
    "                    parent_factor = parent_node if isinstance(parent_node, Factor) else None\n",
    "                    if neighbor_factor == parent_factor:\n",
    "                        continue\n",
    "\n",
    "                    edge = tuple(sorted((current_node.name, neighbor_factor.name)))\n",
    "                    if edge not in visited_edges:\n",
    "                         # Compute Var -> Fac message\n",
    "                         _ = self.variable_to_factor_messages(current_node, neighbor_factor)\n",
    "                         visited_edges.add(edge)\n",
    "                         queue.append((neighbor_factor, current_node)) # Add factor to queue\n",
    "\n",
    "            elif isinstance(current_node, Factor):\n",
    "                # Send messages Factor -> Variable to all neighbors except the one towards parent_node\n",
    "                 for neighbor_variable in current_node.neighbors:\n",
    "                    # The \"parent\" variable is the one connecting to parent_node (if current_node is not root)\n",
    "                    parent_variable = parent_node if isinstance(parent_node, Variable) else None\n",
    "                    if neighbor_variable == parent_variable:\n",
    "                        continue\n",
    "\n",
    "                    edge = tuple(sorted((current_node.name, neighbor_variable.name)))\n",
    "                    if edge not in visited_edges:\n",
    "                         # Compute Fac -> Var message\n",
    "                         _ = self.factor_to_variable_message(current_node, neighbor_variable)\n",
    "                         visited_edges.add(edge)\n",
    "                         queue.append((neighbor_variable, current_node)) # Add variable to queue\n",
    "\n",
    "        print(f\"Backward pass from '{root_variable_name}' complete (messages computed lazily/triggered).\")\n",
    "\n",
    "\n",
    "    def belief_propagation(self, pgm: PGM):\n",
    "        \"\"\"\n",
    "        Executes the full belief propagation algorithm (sum-product) to compute all marginal distributions.\n",
    "\n",
    "        For a tree, this can be achieved by:\n",
    "        1. (Optionally) Performing an explicit forward pass towards an arbitrary root.\n",
    "        2. (Optionally) Performing an explicit backward pass away from that root.\n",
    "        3. Calculating the marginal for each variable using the computed messages.\n",
    "\n",
    "        Alternatively, due to the lazy/recursive nature of the message computation here,\n",
    "        simply requesting the marginal for every variable will ensure all necessary messages\n",
    "        are computed exactly once (due to memoization) across the entire graph. This function\n",
    "        uses the simpler approach of iterating through variables and calling `marginal`.\n",
    "\n",
    "        Args:\n",
    "            pgm (PGM): The PGM object containing the graph structure and factor potentials.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary mapping each variable name (str) to its computed\n",
    "                  marginal distribution (numpy array).\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Running Belief Propagation (Sum-Product) ---\")\n",
    "        all_marginals = {}\n",
    "        variables = pgm.get_variables() # Get the dictionary {name: Variable_object}\n",
    "\n",
    "        # This implicitly triggers all necessary message computations due to recursion and memoization.\n",
    "        print(\"Calculating marginals for all variables (triggers message computations)...\")\n",
    "        if not variables:\n",
    "             print(\"Warning: No variables in PGM.\")\n",
    "             return {}\n",
    "\n",
    "        for var_name, variable_obj in variables.items():\n",
    "            # Compute the marginal for this variable.\n",
    "            # This will trigger recursive computation of all necessary messages.\n",
    "            # Previously computed messages stored in self.messages will be reused.\n",
    "            # print(f\"Calculating marginal for: {var_name}\") # Debug\n",
    "            try:\n",
    "                marginal_dist = self.marginal(variable_obj)\n",
    "                all_marginals[var_name] = marginal_dist\n",
    "                # print(f\"  Marginal p({var_name}) = {marginal_dist}\") # Debug\n",
    "            except Exception as e:\n",
    "                 print(f\"ERROR calculating marginal for variable '{var_name}': {e}\")\n",
    "                 # Optionally re-raise or store None/error indicator\n",
    "                 all_marginals[var_name] = f\"Error: {e}\"\n",
    "\n",
    "\n",
    "        print(\"Belief Propagation complete.\")\n",
    "        return all_marginals"
   ],
   "id": "3d617a80bf56298a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Notes**: Used Gemini 2.5 to fix several errors that appears during debug phase. After that, the entire block of code was refactored, adding some comments and checking for correctness.",
   "id": "319529a79ae23e70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example usage\n",
    "**Apply the belief_propagation method to a given factor graph (page 43 PML notes)**\n",
    "\n",
    "![factor_ex](imgs/factor_example.png)"
   ],
   "id": "eec41c69966cf70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:12:39.124176Z",
     "start_time": "2025-04-13T14:12:39.109031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the graph structure string\n",
    "model_string = \"p(x1,x3)p(x2,x3)p(x3,x4,x5)\"\n",
    "\n",
    "# Create the PGM object\n",
    "pgm = PGM.from_string(model_string)\n",
    "print(\"PGM created with variables:\", list(pgm.get_variables().keys()))\n",
    "print(\"PGM created with factors:\", list(pgm.get_factors().keys()))\n",
    "\n",
    "# Define the factor potentials using the values from the example\n",
    "f1_probs = np.array([[0.3, 0.2],\n",
    "                     [0.1, 0.4]])\n",
    "f1_dist = Distribution(f1_probs, ['x1', 'x3'])\n",
    "\n",
    "f2_probs = np.array([[0.1, 0.5],\n",
    "                     [0.2, 0.2]])\n",
    "f2_dist = Distribution(f2_probs, ['x2', 'x3'])\n",
    "\n",
    "f3_probs = np.array([\n",
    "    [[0.1, 0. ],\n",
    "     [0.1, 0.1]],\n",
    "    [[0.1, 0. ],\n",
    "     [0.2, 0.4]]\n",
    "])\n",
    "f3_dist = Distribution(f3_probs, ['x3', 'x4', 'x5'])\n",
    "\n",
    "# Create the data dictionary mapping factor names to distributions\n",
    "data = {\n",
    "    \"p(x1,x3)\": f1_dist,\n",
    "    \"p(x2,x3)\": f2_dist,\n",
    "    \"p(x3,x4,x5)\": f3_dist,\n",
    "}\n",
    "\n",
    "# Set the distributions in the PGM\n",
    "try:\n",
    "    pgm.set_distributions(data)\n",
    "    print(\"\\nDistributions set successfully.\")\n",
    "    for name, var in pgm.get_variables().items():\n",
    "        print(f\"  Variable '{name}' has dimension {var.dim}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error setting distributions: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during distribution setting: {e}\")\n",
    "\n",
    "# Initialize the Messages class\n",
    "m = Messages()\n",
    "\n",
    "# Run Belief Propagation\n",
    "all_marginals = m.belief_propagation(pgm)\n",
    "\n",
    "# Print the computed marginals\n",
    "print(\"\\n--- Computed Marginal Distributions ---\")\n",
    "if all_marginals:\n",
    "    for var_name in sorted(all_marginals.keys()):\n",
    "        marginal = all_marginals[var_name]\n",
    "        if isinstance(marginal, str) and marginal.startswith(\"Error\"):\n",
    "            print(f\"p({var_name}) = {marginal}\")\n",
    "        else:\n",
    "            print(f\"p({var_name}) = {np.array2string(np.asarray(marginal), precision=4, suppress_small=True)}\")\n",
    "else:\n",
    "    print(\"No marginals computed.\")"
   ],
   "id": "a1e55d6d5fe7a8d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGM created with variables: ['x5', 'x2', 'x4', 'x1', 'x3']\n",
      "PGM created with factors: ['p(x1,x3)', 'p(x2,x3)', 'p(x3,x4,x5)']\n",
      "\n",
      "Distributions set successfully.\n",
      "  Variable 'x5' has dimension 2\n",
      "  Variable 'x2' has dimension 2\n",
      "  Variable 'x4' has dimension 2\n",
      "  Variable 'x1' has dimension 2\n",
      "  Variable 'x3' has dimension 2\n",
      "\n",
      "--- Running Belief Propagation (Sum-Product) ---\n",
      "Calculating marginals for all variables (triggers message computations)...\n",
      "Belief Propagation complete.\n",
      "\n",
      "--- Computed Marginal Distributions ---\n",
      "p(x1) = [0.3788 0.6212]\n",
      "p(x2) = [0.6727 0.3273]\n",
      "p(x3) = [0.1091 0.8909]\n",
      "p(x4) = [0.1636 0.8364]\n",
      "p(x5) = [0.4545 0.5455]\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
